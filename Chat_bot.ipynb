{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gokulaspires92/Multi_lingual_chat_bot/blob/main/Chat_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvdL2CsiZg_2",
        "outputId": "da6f8392-0a83-45c9-a4ea-79dac7d7131f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.5.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
            "changed 22 packages in 2s\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "# Install Streamlit (Fixes: ModuleNotFoundError: No module named 'streamlit')\n",
        "!pip install streamlit numpy\n",
        "\n",
        "# Install FAISS, the core RAG vector library (using the stable CPU version)\n",
        "!pip install faiss-cpu\n",
        "\n",
        "# Install document parsing for .docx files (Fixes: Document import)\n",
        "!pip install python-docx\n",
        "\n",
        "# Install the Sentence Transformer model library (for embeddings)\n",
        "!pip install sentence-transformers\n",
        "\n",
        "# Install localtunnel to expose the Streamlit web app\n",
        "!npm install -g localtunnel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cTQaxDoZegF",
        "outputId": "3c3f765b-dfbd-40f5-a4a1-a98526410eb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import faiss\n",
        "from docx import Document\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "# We must import SentenceTransformer for local RAG\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import re\n",
        "import json\n",
        "\n",
        "# Suppress warnings\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "# --- Streamlit Configuration ---\n",
        "# Switching to a slightly smaller model (L12-v2) to improve loading stability.\n",
        "st.set_page_config(page_title=\"HCL GUVI Stable RAG Chatbot (English Only)\", layout=\"wide\")\n",
        "\n",
        "# --- Global Configuration ---\n",
        "DOCUMENT_PATH = \"Chatbot.docx\"\n",
        "# Using the slightly faster/smaller 'all-MiniLM-L12-v2' model instead of L6-v2 for robustness\n",
        "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
        "\n",
        "# --- Utility Functions ---\n",
        "\n",
        "def split_text_into_chunks(raw_text):\n",
        "    \"\"\"Splits raw text into sentence chunks for indexing.\"\"\"\n",
        "\n",
        "    # Simple sentence tokenizer using regex\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', raw_text)\n",
        "    sentences = [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "    if not sentences:\n",
        "        try:\n",
        "            nltk.download('punkt', quiet=True)\n",
        "        except:\n",
        "            pass # Ignore download errors if already present\n",
        "\n",
        "        sentences = sent_tokenize(raw_text)\n",
        "        sentences = [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "    return sentences\n",
        "\n",
        "# --- Caching and Initialization Functions ---\n",
        "@st.cache_resource(show_spinner=False)\n",
        "def initialize_knowledge_base():\n",
        "    \"\"\"Initializes the FAISS index, text chunks, and embedding model with visual progress.\"\"\"\n",
        "\n",
        "    status_container = st.container()\n",
        "    progress_bar = status_container.progress(0, text=\"Initializing...\")\n",
        "\n",
        "    try:\n",
        "        # 1. Load and process document\n",
        "        progress_bar.progress(10, text=\"1/4: Extracting text from DOCX...\")\n",
        "\n",
        "        document = Document(DOCUMENT_PATH)\n",
        "        raw_text = \"\\n\".join([paragraph.text for paragraph in document.paragraphs]).lower()\n",
        "\n",
        "        # 2. Tokenize into sentences (chunks)\n",
        "        progress_bar.progress(30, text=\"2/4: Tokenizing document into sentences...\")\n",
        "        sentences = split_text_into_chunks(raw_text)\n",
        "\n",
        "        if not sentences:\n",
        "            status_container.error(f\"The document at '{DOCUMENT_PATH}' is empty or could not be processed.\")\n",
        "            return None, None, None\n",
        "\n",
        "        status_container.info(f\"Knowledge base loaded with {len(sentences)} sentences.\")\n",
        "\n",
        "        # 3. Load Embedding Model (L12-v2)\n",
        "        progress_bar.progress(50, text=\"3/4: Downloading/Loading Sentence Transformer model (L12-v2)...\")\n",
        "        embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
        "\n",
        "        # 4. Create Embeddings and FAISS Index\n",
        "        progress_bar.progress(70, text=\"4/4: Creating vector index (FAISS)...\")\n",
        "        embeddings = embedding_model.encode(sentences, convert_to_tensor=False)\n",
        "        embeddings = np.array(embeddings).astype('float32')\n",
        "\n",
        "        dimension = embeddings.shape[1]\n",
        "        index = faiss.IndexFlatL2(dimension)\n",
        "        index.add(embeddings)\n",
        "\n",
        "        progress_bar.progress(100, text=\"Initialization Complete!\")\n",
        "        status_container.success(\"Knowledge base (FAISS index) built successfully! App is ready.\")\n",
        "        time.sleep(1)\n",
        "        status_container.empty()\n",
        "\n",
        "        return index, sentences, embedding_model\n",
        "    except Exception as e:\n",
        "        print(f\"UNHANDLED EXCEPTION in initialize_knowledge_base: {e}\", file=sys.stderr)\n",
        "        progress_bar.progress(0, text=\"Initialization Failed.\")\n",
        "        status_container.error(f\"A critical error occurred during knowledge base initialization. Error: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# --- Core Local RAG Logic ---\n",
        "\n",
        "def retrieve_context(query_embedding, index, sentences, k=3):\n",
        "    \"\"\"Retrieves the top k most relevant sentences from the FAISS index.\"\"\"\n",
        "    try:\n",
        "        query_vector = np.array(query_embedding).astype('float32').reshape(1, -1)\n",
        "        if index is None or index.ntotal == 0:\n",
        "            return \"\"\n",
        "\n",
        "        D, I = index.search(query_vector, k)\n",
        "        context = [sentences[i] for i in I[0] if i < len(sentences)]\n",
        "        return \"\\n\".join(context)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during context retrieval: {e}\", file=sys.stderr)\n",
        "        return \"\"\n",
        "\n",
        "def generate_local_rag_response(prompt: str, context: str):\n",
        "    \"\"\"\n",
        "    Generates a response using simple, local, template-based logic\n",
        "    (Fallback for no local LLM/Q&A model).\n",
        "    \"\"\"\n",
        "    if not context:\n",
        "        return \"I am sorry, I couldn't find any relevant information in the knowledge document to answer your question.\"\n",
        "\n",
        "    response = (\n",
        "        f\"Based on the knowledge document, here is the relevant context for your query:\\n\\n\"\n",
        "        f\"**Question:** *{prompt}*\\n\\n\"\n",
        "        f\"**Relevant Context Found:**\\n> {context.replace('\\n', '\\n> ')}\\n\\n\"\n",
        "        f\"*(This simple RAG system provides the source context directly, as it avoids using a separate local LLM/Q&A model to meet environmental constraints.)*\"\n",
        "    )\n",
        "    return response\n",
        "\n",
        "# --- Main Chatbot Application ---\n",
        "def run_chatbot(index, sentences, embedding_model):\n",
        "    \"\"\"The main Streamlit application logic.\"\"\"\n",
        "    st.markdown(\"\"\"\n",
        "        <div style='text-align: center; background-color: #f0f2f6; padding: 10px; border-radius: 10px;'>\n",
        "            <h1 style='color: #4a4a4a; font-size: 1.8em; margin: 0;'>\n",
        "                HCL GUVI Stable RAG Chatbot (English Only)\n",
        "            </h1>\n",
        "            <p style='color: #6c757d; margin: 0;'>\n",
        "                Trained on the <b>Chatbot.docx</b> document using local vector search.\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Initialize chat history\n",
        "    if \"messages\" not in st.session_state:\n",
        "        st.session_state.messages = []\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": \"Hello! I am the HCL GUVI Knowledge Bot. I can answer questions about the document, but please ask in **English**.\"})\n",
        "\n",
        "    # Display chat messages from history on app rerun\n",
        "    for message in st.session_state.messages:\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "    # We are replacing the problematic st.chat_input with a reliable st.text_input.\n",
        "    # The key='input_key' ensures the input is persistent across runs.\n",
        "    prompt = st.text_input(\"Ask a question in English (e.g., 'What is GUVI?')\", key='input_key', on_change=handle_input)\n",
        "\n",
        "    # We use a button to explicitly trigger the action, which is more reliable in this environment.\n",
        "    st.button(\"Send Query\", on_click=handle_input)\n",
        "\n",
        "    # Logic is handled by the callback function to prevent running the entire script multiple times\n",
        "    # when text_input state changes, but we still need to process the prompt if it exists.\n",
        "    if st.session_state.get('new_prompt'):\n",
        "        process_prompt(st.session_state['new_prompt'], index, sentences, embedding_model)\n",
        "        st.session_state['new_prompt'] = None # Clear the prompt after processing\n",
        "\n",
        "def handle_input():\n",
        "    \"\"\"Handles the user input when Enter is pressed or the button is clicked.\"\"\"\n",
        "    # Check if the text input box has content and hasn't been processed yet\n",
        "    if st.session_state['input_key'] and st.session_state['input_key'] != st.session_state.get('last_prompt', ''):\n",
        "        st.session_state['new_prompt'] = st.session_state['input_key']\n",
        "        st.session_state['last_prompt'] = st.session_state['input_key']\n",
        "        st.session_state['input_key'] = '' # Clear the input box immediately\n",
        "\n",
        "def process_prompt(prompt, index, sentences, embedding_model):\n",
        "    \"\"\"Processes the user's query and generates a response.\"\"\"\n",
        "    if prompt:\n",
        "        # Add user message to chat history\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            with st.spinner(\"Processing (Local RAG)...\"):\n",
        "\n",
        "                # a. Embed the query\n",
        "                query_embedding = embedding_model.encode([prompt], convert_to_tensor=False)[0]\n",
        "\n",
        "                # b. Retrieve the context\n",
        "                context = retrieve_context(query_embedding, index, sentences)\n",
        "\n",
        "                # c. Generate the local response\n",
        "                final_response = generate_local_rag_response(prompt, context)\n",
        "\n",
        "                # Display the final response\n",
        "                st.markdown(final_response)\n",
        "\n",
        "        # Add assistant response to chat history\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": final_response})\n",
        "\n",
        "\n",
        "# --- Application Entry Point ---\n",
        "if not os.path.exists(DOCUMENT_PATH):\n",
        "    st.error(f\"FATAL ERROR: The required document '{DOCUMENT_PATH}' was not found. Please ensure it is uploaded.\")\n",
        "else:\n",
        "    # Initialize knowledge base (the only component that requires local loading)\n",
        "    index, sentences, embedding_model = initialize_knowledge_base()\n",
        "\n",
        "    # Run application if successful\n",
        "    if index is not None and embedding_model is not None:\n",
        "        run_chatbot(index, sentences, embedding_model)\n",
        "    else:\n",
        "        st.error(\"Application could not fully initialize. Check the logs.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "97ChvZm2bGN4",
        "outputId": "c97be3cb-6f15-4fb5-eab8-c545d1dd6287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.68.62.88:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0Kyour url is: https://wild-cobras-win.loca.lt\n",
            "2025-09-30 13:10:17.580669: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759237817.649671   11708 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1759237817.662985   11708 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1759237817.714735   11708 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759237817.714819   11708 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759237817.714828   11708 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1759237817.714834   11708 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-30 13:10:17.731787: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "!pkill -f streamlit\n",
        "!streamlit run app.py --server.port 8501 & sleep 3 && npx localtunnel --port 8501\n",
        "'''3.  When the application loads, you should see the **input box and the button** directly on the main page. Type your question and click **\"Send Query\"**.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZjef2NCuPph"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}